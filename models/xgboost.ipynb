{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import shap \n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "shap.initjs()\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "\n",
    "# Navigate two directories back\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "\n",
    "# define the data directory\n",
    "data_dir = parent_dir + \"/data/\"\n",
    "\n",
    "# This creates the full path to the output directory\n",
    "Output = \"results/\"\n",
    "output_dir = os.path.join(parent_dir, Output)\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Path to the 'src' directory\n",
    "src_path = os.path.join(parent_dir, 'src')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each entry in the 'src' directory\n",
    "for item in os.listdir(src_path):\n",
    "    full_path = os.path.join(src_path, item)\n",
    "    # Check if the entry is a directory\n",
    "    if os.path.isdir(full_path):\n",
    "        # Add the directory to sys.path\n",
    "        sys.path.append(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv(data_dir + \"cleaned/no_nan_ordinal_encoded.csv\")\n",
    "\n",
    "int_cols = np.setxor1d(np.array(data.columns), np.array(['AMT_CREDIT', 'AMT_INCOME_TOTAL']))\n",
    "data[int_cols] = data[int_cols].astype(int)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining categorical columns\n",
    "selected_columns = []\n",
    "for column in data.columns:\n",
    "    unique_values = data[column].nunique()\n",
    "    if unique_values <= 10 and unique_values > 2:\n",
    "        selected_columns.append(column)\n",
    "\n",
    "data[selected_columns] = data[selected_columns].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the categorical columns\n",
    "from fn_encoding import one_hot_encode\n",
    "\n",
    "data = one_hot_encode(data, selected_columns)\n",
    "data.replace({True: 1, False: 0}, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop(columns=[\"TARGET\", \"STATUS\"])\n",
    "y = data[\"TARGET\"]\n",
    "\n",
    "\n",
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)\n",
    "del data, X, y\n",
    "X_train.shape, X_test.shape, y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "run_dir = os.path.join(parent_dir, 'model_runs')\n",
    "run_dir = os.path.join(run_dir, 'randomforest')\n",
    "\n",
    "if not os.path.exists(run_dir):\n",
    "    os.makedirs(run_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB Classifier\n",
    "xg_cl = xgb.XGBClassifier(learning_rate = 0.9, max_depth = 1000, n_estimators = 1000)\n",
    "\n",
    "# Fit the classifier to the training set\n",
    "xg_cl.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predict the labels of the test set: preds\n",
    "predictions = xg_cl.predict(X_test)\n",
    "\n",
    "# Assuming y_pred contains the predicted values and y_test contains the actual values\n",
    "recall = recall_score(y_test, predictions)\n",
    "\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    \"colsample_bytree\": uniform(0.7, 0.3),\n",
    "    \"gamma\": uniform(0, 0.5),\n",
    "    \"learning_rate\": uniform(0.03, 0.3), # default 0.1 \n",
    "    \"max_depth\": randint(2, 6), # default 3\n",
    "    \"n_estimators\": randint(100, 150), # default 100\n",
    "    \"subsample\": uniform(0.6, 0.4)\n",
    "    }\n",
    "\n",
    "# Define the hyperparameter distributions\n",
    "param_dist = {\n",
    "    #'max_depth': stats.randint(3, 10),\n",
    "    'learning_rate': stats.uniform(0.01, 0.9),\n",
    "    #'subsample': stats.uniform(0.5, 0.5),\n",
    "    #'n_estimators':stats.randint(50, 200)\n",
    "}\n",
    "\n",
    "# Create the XGBoost model object\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=1000)\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb_model, param_distributions=param_dist, n_iter=10, cv=5, scoring='recall')\n",
    "\n",
    "# Fit the RandomizedSearchCV object to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best set of hyperparameters and the corresponding score\n",
    "print(\"Best set of hyperparameters: \", random_search.best_params_)\n",
    "print(\"Best score: \", random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    #'max_depth': range(3, 10, 1),\n",
    "    'n_estimators': range(100, 10000, 500),\n",
    "    'learning_rate': np.logspace(np.log10(0.01), np.log10(10), num=20),\n",
    "    #'subsample': [0.5, 0.7, 1]\n",
    "    }\n",
    "\n",
    "# Create the XGBoost model object\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, cv=5, scoring='recall')\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best set of hyperparameters and the corresponding score\n",
    "print(\"Best set of hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, f1_score, confusion_matrix, recall_score, precision_score\n",
    "\n",
    "params = grid_search.best_params_\n",
    "# Initialize the XGBClassifier with the best parameters\n",
    "model = xgb.XGBClassifier(n_estimators=1000,**params)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Assuming y_pred contains the predicted values and y_test contains the actual values\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PerformanceMetrics import plot_roc\n",
    "\n",
    "experiment_path = os.path.join(parent_dir, 'model_runs/xgboost')\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "f = plot_roc(model, X_test, y_test)\n",
    "f.savefig(experiment_path + '/roc_curve-gridsearch0.png', dpi=600, format='png',bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
